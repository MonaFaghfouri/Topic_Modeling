{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonaFaghfouri/Topic_Modeling/blob/main/Topic_Modeling_by_Time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install compatible versions of required libraries\n",
        "!pip install --upgrade --force-reinstall numpy==1.23.5 pandas==1.5.3 gensim openpyxl -q"
      ],
      "metadata": {
        "id": "QPlzUFIOIQrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# monthly_keywords_with_weights: Extracting and weighting keywords by month"
      ],
      "metadata": {
        "id": "OSJaumP__EQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from collections import Counter, defaultdict\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "import ast\n",
        "import re\n",
        "\n",
        "# Load data\n",
        "df = pd.read_excel(next(iter(uploaded)))\n",
        "\n",
        "# Convert token column from string to list\n",
        "df[\"Tokens\"] = df.iloc[:, 1].apply(ast.literal_eval)\n",
        "\n",
        "# Convert date column to datetime\n",
        "dates = pd.to_datetime(df.iloc[:, 2], errors='coerce')\n",
        "df[\"Month\"] = dates.dt.strftime(\"%B\")\n",
        "\n",
        "# Define month order\n",
        "custom_month_order = [\n",
        "    \"April\", \"May\", \"June\", \"July\", \"August\", \"September\",\n",
        "    \"October\", \"November\", \"December\", \"January\", \"February\"\n",
        "]\n",
        "\n",
        "# Function to clean tokens\n",
        "def clean_tokens(tokens):\n",
        "    cleaned = []\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        token = re.sub(r'\\W+', '', token)\n",
        "        if len(token) > 2 and token.isalpha():\n",
        "            cleaned.append(token)\n",
        "    return cleaned\n",
        "\n",
        "# Monthly LDA topic modeling\n",
        "month_top_keywords = []\n",
        "\n",
        "for month in custom_month_order:\n",
        "    month_df = df[df[\"Month\"] == month]\n",
        "    if not month_df.empty:\n",
        "        month_tokens = month_df[\"Tokens\"].apply(clean_tokens).tolist()\n",
        "        month_tokens = [tokens for tokens in month_tokens if tokens]\n",
        "\n",
        "        dictionary = corpora.Dictionary(month_tokens)\n",
        "        dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
        "        corpus = [dictionary.doc2bow(tokens) for tokens in month_tokens]\n",
        "\n",
        "        if len(dictionary) == 0 or all(len(doc) == 0 for doc in corpus):\n",
        "            continue\n",
        "\n",
        "        lda_model = LdaModel(\n",
        "            corpus=corpus,\n",
        "            id2word=dictionary,\n",
        "            num_topics=5,\n",
        "            random_state=42,\n",
        "            passes=15,\n",
        "            iterations=100,\n",
        "            minimum_probability=0.01\n",
        "        )\n",
        "\n",
        "        # Aggregate keyword weights across all topics\n",
        "        keyword_weights = defaultdict(float)\n",
        "\n",
        "        for topic_id in range(lda_model.num_topics):\n",
        "            topic_terms = lda_model.show_topic(topic_id, topn=10)\n",
        "            for word, weight in topic_terms:\n",
        "                keyword_weights[word] += weight\n",
        "\n",
        "        # Normalize weights (optional, can be removed)\n",
        "        total_weight = sum(keyword_weights.values())\n",
        "        normalized_keywords = {\n",
        "            word: round(weight / total_weight, 4) if total_weight else 0\n",
        "            for word, weight in keyword_weights.items()\n",
        "        }\n",
        "\n",
        "        sorted_keywords = sorted(normalized_keywords.items(), key=lambda x: x[1], reverse=True)\n",
        "        formatted_keywords = [f\"{word} {weight}\" for word, weight in sorted_keywords[:10]]\n",
        "\n",
        "        dominant_keyword = sorted_keywords[0][0] if sorted_keywords else \"\"\n",
        "\n",
        "        month_top_keywords.append({\n",
        "            \"Month\": month,\n",
        "            \"Top Keywords\": \", \".join(formatted_keywords),\n",
        "            \"Dominant Keyword\": dominant_keyword\n",
        "        })\n",
        "\n",
        "# Save results\n",
        "result_df = pd.DataFrame(month_top_keywords)\n",
        "output_filename = \"monthly_keywords_with_weights.xlsx\"\n",
        "result_df.to_excel(output_filename, index=False)\n",
        "\n",
        "# Download result\n",
        "files.download(output_filename)\n"
      ],
      "metadata": {
        "id": "5qMo--vS_FL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# monthly_peakday_topics_LDA_weighted: Extracting LDA-weighted topics for monthly peak days"
      ],
      "metadata": {
        "id": "pG45qZvkIMVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import ast\n",
        "from collections import Counter\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from google.colab import files\n",
        "\n",
        "# Upload file\n",
        "print(\"Please upload your Excel file:\")\n",
        "uploaded = files.upload()\n",
        "df = pd.read_excel(next(iter(uploaded)))\n",
        "\n",
        "# Convert token strings to list\n",
        "df[\"Tokens\"] = df.iloc[:, 1].apply(ast.literal_eval)\n",
        "\n",
        "# Convert date to datetime\n",
        "df[\"datetime\"] = pd.to_datetime(df.iloc[:, 2], errors='coerce')\n",
        "df[\"date\"] = df[\"datetime\"].dt.date\n",
        "df[\"month\"] = df[\"datetime\"].dt.strftime('%Y-%m')\n",
        "\n",
        "# Token cleaning function\n",
        "def clean_tokens(tokens):\n",
        "    cleaned = []\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        token = re.sub(r'\\W+', '', token)\n",
        "        if len(token) > 2 and token.isalpha():\n",
        "            cleaned.append(token)\n",
        "    return cleaned\n",
        "\n",
        "# Find the peak day of each month\n",
        "monthly_peaks = df.groupby(\"month\")[\"date\"].apply(lambda x: x.value_counts().idxmax())\n",
        "\n",
        "# Topic modeling for each peak day\n",
        "results = []\n",
        "\n",
        "for month, peak_day in monthly_peaks.items():\n",
        "    peak_df = df[df[\"date\"] == peak_day]\n",
        "    tokens_list = peak_df[\"Tokens\"].apply(clean_tokens).tolist()\n",
        "    tokens_list = [t for t in tokens_list if t]\n",
        "\n",
        "    if len(tokens_list) == 0:\n",
        "        continue\n",
        "\n",
        "    # Build dictionary and remove rare/common tokens\n",
        "    dictionary = corpora.Dictionary(tokens_list)\n",
        "    dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
        "    corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
        "\n",
        "    if len(dictionary) == 0 or all(len(doc) == 0 for doc in corpus):\n",
        "        continue\n",
        "\n",
        "    # Train LDA model\n",
        "    lda_model = LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=dictionary,\n",
        "        num_topics=5,\n",
        "        random_state=42,\n",
        "        passes=15,\n",
        "        iterations=100,\n",
        "        minimum_probability=0.01\n",
        "    )\n",
        "\n",
        "    # Extract keywords with their normalized weights\n",
        "    keyword_counter = Counter()\n",
        "    for topic_id in range(lda_model.num_topics):\n",
        "        words = lda_model.show_topic(topic_id, topn=10)\n",
        "        keyword_counter.update(dict(words))\n",
        "\n",
        "    total_score = sum(keyword_counter.values())\n",
        "    if total_score == 0:\n",
        "        continue\n",
        "\n",
        "    # Normalize and sort keywords\n",
        "    normalized_keywords = [(word, round(score / total_score, 3)) for word, score in keyword_counter.most_common(10)]\n",
        "    formatted_keywords = \", \".join([f\"{word} {score}\" for word, score in normalized_keywords])\n",
        "    dominant = normalized_keywords[0][0] if normalized_keywords else \"Unknown\"\n",
        "\n",
        "    results.append((month, formatted_keywords, dominant))\n",
        "\n",
        "# Save results\n",
        "result_df = pd.DataFrame(results, columns=[\"Month\", \"Top 10 Keywords (with weights)\", \"Dominant Keyword\"])\n",
        "output_file = \"monthly_peakday_topics_LDA_weighted.xlsx\"\n",
        "result_df.to_excel(output_file, index=False)\n",
        "\n",
        "# Download file\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "id": "EKdxKCSdIMw5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}