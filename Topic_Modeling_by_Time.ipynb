{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbpQBhtU1wt+sW2/R/DuCu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonaFaghfouri/Topic_Modeling/blob/main/Topic_Modeling_by_Time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install compatible versions of required libraries\n",
        "!pip install --upgrade --force-reinstall numpy==1.23.5 pandas==1.5.3 gensim openpyxl -q"
      ],
      "metadata": {
        "id": "QPlzUFIOIQrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "import ast\n",
        "import re\n",
        "\n",
        "# Load data\n",
        "df = pd.read_excel(next(iter(uploaded)))\n",
        "\n",
        "# Convert token column from string to list\n",
        "df[\"Tokens\"] = df.iloc[:, 1].apply(ast.literal_eval)\n",
        "\n",
        "# Convert date column to datetime\n",
        "dates = pd.to_datetime(df.iloc[:, 2], errors='coerce')\n",
        "df[\"Month\"] = dates.dt.strftime(\"%B\")\n",
        "\n",
        "# Define month order\n",
        "custom_month_order = [\n",
        "    \"April\", \"May\", \"June\", \"July\", \"August\", \"September\",\n",
        "    \"October\", \"November\", \"December\", \"January\", \"February\"\n",
        "]\n",
        "\n",
        "# Function to clean tokens\n",
        "def clean_tokens(tokens):\n",
        "    cleaned = []\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        token = re.sub(r'\\W+', '', token)  # Remove non-alphanumeric\n",
        "        if len(token) > 2 and token.isalpha():  # Remove short/non-alpha tokens\n",
        "            cleaned.append(token)\n",
        "    return cleaned\n",
        "\n",
        "# Monthly LDA topic modeling\n",
        "month_top_keywords = []\n",
        "\n",
        "for month in custom_month_order:\n",
        "    month_df = df[df[\"Month\"] == month]\n",
        "    if not month_df.empty:\n",
        "        month_tokens = month_df[\"Tokens\"].apply(clean_tokens).tolist()\n",
        "\n",
        "        # Remove empty token lists\n",
        "        month_tokens = [tokens for tokens in month_tokens if tokens]\n",
        "\n",
        "        # Build dictionary and filter extremes\n",
        "        dictionary = corpora.Dictionary(month_tokens)\n",
        "        dictionary.filter_extremes(no_below=2, no_above=0.8)  # filter rare/common tokens\n",
        "        corpus = [dictionary.doc2bow(tokens) for tokens in month_tokens]\n",
        "\n",
        "        if len(dictionary) == 0 or all(len(doc) == 0 for doc in corpus):\n",
        "            continue  # Skip if no valid data left after filtering\n",
        "\n",
        "        # Train LDA model\n",
        "        lda_model = LdaModel(\n",
        "            corpus=corpus,\n",
        "            id2word=dictionary,\n",
        "            num_topics=5,\n",
        "            random_state=42,\n",
        "            passes=15,\n",
        "            iterations=100,\n",
        "            minimum_probability=0.01\n",
        "        )\n",
        "\n",
        "        # Aggregate keywords from all topics\n",
        "        keyword_counter = Counter()\n",
        "        for topic_id in range(lda_model.num_topics):\n",
        "            topic_keywords = lda_model.show_topic(topic_id, topn=10)\n",
        "            keyword_counter.update([word for word, _ in topic_keywords])\n",
        "\n",
        "        top_keywords = [word for word, _ in keyword_counter.most_common(10)]\n",
        "        dominant_keyword = top_keywords[0] if top_keywords else \"\"\n",
        "\n",
        "        month_top_keywords.append({\n",
        "            \"Month\": month,\n",
        "            \"Top Keywords\": \", \".join(top_keywords),\n",
        "            \"Dominant Keyword\": dominant_keyword\n",
        "        })\n",
        "\n",
        "# Save results\n",
        "result_df = pd.DataFrame(month_top_keywords)\n",
        "output_filename = \"monthly_keywords_LDA_Improved.xlsx\"\n",
        "result_df.to_excel(output_filename, index=False)\n",
        "\n",
        "# Download result\n",
        "files.download(output_filename)\n"
      ],
      "metadata": {
        "id": "jZOPIEntY0Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arabic_reshaper python-bidi\n",
        "\n",
        "import pandas as pd\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "from collections import Counter\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "import ast\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the Excel file\n",
        "print(\"Please upload your Excel file:\")\n",
        "uploaded = files.upload()\n",
        "df = pd.read_excel(next(iter(uploaded)))\n",
        "\n",
        "# Convert token column from string to list\n",
        "df[\"Tokens\"] = df.iloc[:, 1].apply(ast.literal_eval)\n",
        "\n",
        "# Convert date column to datetime\n",
        "df[\"datetime\"] = pd.to_datetime(df.iloc[:, 2], errors='coerce')\n",
        "df[\"date\"] = df[\"datetime\"].dt.date\n",
        "df[\"month\"] = df[\"datetime\"].dt.strftime('%Y-%m')\n",
        "\n",
        "# Clean tokens function (similar to first script)\n",
        "def clean_tokens(tokens):\n",
        "    cleaned = []\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        token = re.sub(r'\\W+', '', token)\n",
        "        if len(token) > 2 and token.isalpha():\n",
        "            cleaned.append(token)\n",
        "    return cleaned\n",
        "\n",
        "# Find the peak day for each month\n",
        "monthly_peaks = df.groupby(\"month\")[\"date\"].apply(lambda x: x.value_counts().idxmax())\n",
        "\n",
        "# LDA topic modeling for each peak day\n",
        "results = []\n",
        "\n",
        "for month, peak_day in monthly_peaks.items():\n",
        "    peak_df = df[df[\"date\"] == peak_day]\n",
        "    tokens_list = peak_df[\"Tokens\"].apply(clean_tokens).tolist()\n",
        "    tokens_list = [t for t in tokens_list if t]  # remove empty\n",
        "\n",
        "    if len(tokens_list) == 0:\n",
        "        continue\n",
        "\n",
        "    # Create dictionary and filter extremes\n",
        "    dictionary = corpora.Dictionary(tokens_list)\n",
        "    dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
        "    corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
        "\n",
        "    if len(dictionary) == 0 or all(len(doc) == 0 for doc in corpus):\n",
        "        continue\n",
        "\n",
        "    # Fit LDA model\n",
        "    lda_model = LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=dictionary,\n",
        "        num_topics=5,\n",
        "        random_state=42,\n",
        "        passes=15,\n",
        "        iterations=100,\n",
        "        minimum_probability=0.01\n",
        "    )\n",
        "\n",
        "    # Collect keywords from all topics\n",
        "    keyword_counter = Counter()\n",
        "    for topic_id in range(lda_model.num_topics):\n",
        "        words = lda_model.show_topic(topic_id, topn=10)\n",
        "        keyword_counter.update([word for word, _ in words])\n",
        "\n",
        "    top_10_words = [get_display(arabic_reshaper.reshape(word)) for word, _ in keyword_counter.most_common(10)]\n",
        "    dominant = top_10_words[0] if top_10_words else \"Unknown\"\n",
        "\n",
        "    results.append((month, \", \".join(top_10_words), dominant))\n",
        "\n",
        "# Save result to Excel file\n",
        "result_df = pd.DataFrame(results, columns=[\"Month\", \"Top 10 Keywords\", \"Dominant Keyword\"])\n",
        "output_file = \"monthly_peakday_topics_LDA.xlsx\"\n",
        "result_df.to_excel(output_file, index=False)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_file)\n"
      ],
      "metadata": {
        "id": "bzpgF4WRiFLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import ast\n",
        "from collections import Counter\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from google.colab import files\n",
        "\n",
        "# Upload file\n",
        "print(\"Please upload your Excel file:\")\n",
        "uploaded = files.upload()\n",
        "df = pd.read_excel(next(iter(uploaded)))\n",
        "\n",
        "# Convert token strings to list\n",
        "df[\"Tokens\"] = df.iloc[:, 1].apply(ast.literal_eval)\n",
        "\n",
        "# Convert date to datetime\n",
        "df[\"datetime\"] = pd.to_datetime(df.iloc[:, 2], errors='coerce')\n",
        "df[\"date\"] = df[\"datetime\"].dt.date\n",
        "df[\"month\"] = df[\"datetime\"].dt.strftime('%Y-%m')\n",
        "\n",
        "# Token cleaning function\n",
        "def clean_tokens(tokens):\n",
        "    cleaned = []\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        token = re.sub(r'\\W+', '', token)\n",
        "        if len(token) > 2 and token.isalpha():\n",
        "            cleaned.append(token)\n",
        "    return cleaned\n",
        "\n",
        "# Find the peak day of each month\n",
        "monthly_peaks = df.groupby(\"month\")[\"date\"].apply(lambda x: x.value_counts().idxmax())\n",
        "\n",
        "# Topic modeling for each peak day\n",
        "results = []\n",
        "\n",
        "for month, peak_day in monthly_peaks.items():\n",
        "    peak_df = df[df[\"date\"] == peak_day]\n",
        "    tokens_list = peak_df[\"Tokens\"].apply(clean_tokens).tolist()\n",
        "    tokens_list = [t for t in tokens_list if t]\n",
        "\n",
        "    if len(tokens_list) == 0:\n",
        "        continue\n",
        "\n",
        "    # Build dictionary and remove rare/common tokens\n",
        "    dictionary = corpora.Dictionary(tokens_list)\n",
        "    dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
        "    corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
        "\n",
        "    if len(dictionary) == 0 or all(len(doc) == 0 for doc in corpus):\n",
        "        continue\n",
        "\n",
        "    # Train LDA model\n",
        "    lda_model = LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=dictionary,\n",
        "        num_topics=5,\n",
        "        random_state=42,\n",
        "        passes=15,\n",
        "        iterations=100,\n",
        "        minimum_probability=0.01\n",
        "    )\n",
        "\n",
        "    # Extract keywords\n",
        "    keyword_counter = Counter()\n",
        "    for topic_id in range(lda_model.num_topics):\n",
        "        words = lda_model.show_topic(topic_id, topn=10)\n",
        "        keyword_counter.update([word for word, _ in words])\n",
        "\n",
        "    top_10_words = [word for word, _ in keyword_counter.most_common(10)]\n",
        "    dominant = top_10_words[0] if top_10_words else \"Unknown\"\n",
        "\n",
        "    results.append((month, \", \".join(top_10_words), dominant))\n",
        "\n",
        "# Save results\n",
        "result_df = pd.DataFrame(results, columns=[\"Month\", \"Top 10 Keywords\", \"Dominant Keyword\"])\n",
        "output_file = \"monthly_peakday_topics_LDA_no_reshaper.xlsx\"\n",
        "result_df.to_excel(output_file, index=False)\n",
        "\n",
        "# Download file\n",
        "files.download(output_file)\n"
      ],
      "metadata": {
        "id": "ovRMHHADfrvI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}