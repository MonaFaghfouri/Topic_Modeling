{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonaFaghfouri/Topic_Modeling/blob/main/Topic_Modeling_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  networkx==2.8 matplotlib==3.5.3\n",
        "!pip install --upgrade --force-reinstall numpy pandas\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n",
        "!pip install numpy==1.24.4 --force-reinstall\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n",
        "!pip install arabic-reshaper python-bidi"
      ],
      "metadata": {
        "id": "uFNNzq5Yivjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4 --force-reinstall\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "id": "goVmk3P27O7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!pip install --quiet pandas networkx matplotlib python-louvain openpyxl arabic-reshaper python-bidi\n",
        "\n",
        "# ---- Import libraries ----\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import community.community_louvain as community_louvain\n",
        "from google.colab import files\n",
        "import ast\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# ---- Upload font file ----\n",
        "print(\"Please upload the B-Nazanin.ttf font file\")\n",
        "uploaded_font = files.upload()\n",
        "font_path = next(iter(uploaded_font))  # filename\n",
        "font_prop = fm.FontProperties(fname=font_path)\n",
        "\n",
        "# ---- Upload Excel file ----\n",
        "print(\"Please upload the Excel file containing tokenized tweets in the second column...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ---- Read and parse data ----\n",
        "df = pd.read_excel(next(iter(uploaded)))\n",
        "texts = df.iloc[:, 1].astype(str).apply(ast.literal_eval).tolist()\n",
        "texts = [doc for doc in texts if isinstance(doc, list) and len(doc) > 0]\n",
        "\n",
        "# ---- Helper function to verify token format ----\n",
        "def assert_tokenized_lists(texts):\n",
        "    for idx, item in enumerate(texts):\n",
        "        if not isinstance(item, list):\n",
        "            raise ValueError(f\"Row {idx} is not a list: {item}\")\n",
        "        if not all(isinstance(token, str) for token in item):\n",
        "            raise ValueError(f\"Row {idx} contains non-string tokens: {item}\")\n",
        "    print(\"âœ… All rows are valid lists of string tokens.\")\n",
        "\n",
        "assert_tokenized_lists(texts)\n",
        "\n",
        "# ---- Function to build word co-occurrence graph ----\n",
        "def construct_word_cooccurrence_graph(dataset, window_size=5):\n",
        "    G = nx.Graph()\n",
        "    for tokens in dataset:\n",
        "        for i, word in enumerate(tokens):\n",
        "            for j in range(max(0, i - window_size), min(len(tokens), i + window_size + 1)):\n",
        "                if i != j:\n",
        "                    u, v = word, tokens[j]\n",
        "                    if G.has_edge(u, v):\n",
        "                        G[u][v]['weight'] += 1\n",
        "                    else:\n",
        "                        G.add_edge(u, v, weight=1)\n",
        "    return G\n",
        "\n",
        "# ---- Graph pruning function ----\n",
        "def prune_graph(graph, min_frequency=5, max_connections_per_node=30):\n",
        "    G = graph.copy()\n",
        "    for u, v, data in list(G.edges(data=True)):\n",
        "        if data['weight'] < min_frequency:\n",
        "            G.remove_edge(u, v)\n",
        "    low_degree_nodes = [n for n, d in G.degree() if d < min_frequency]\n",
        "    G.remove_nodes_from(low_degree_nodes)\n",
        "    if len(G.nodes) == 0:\n",
        "        print(\"âš ï¸ Graph is empty after pruning.\")\n",
        "        return G\n",
        "    G = nx.k_core(G, k=min(3, max_connections_per_node))\n",
        "    return G\n",
        "\n",
        "# ---- Community detection ----\n",
        "def detect_communities(graph, resolution=1.0):\n",
        "    if nx.is_empty(graph):\n",
        "        return {}\n",
        "    return community_louvain.best_partition(graph, resolution=resolution)\n",
        "\n",
        "# ---- Graph visualization ----\n",
        "def visualize_graph(graph, partition, font_prop):\n",
        "    if not partition:\n",
        "        print(\"âš ï¸ Empty graph or no communities found.\")\n",
        "        return\n",
        "\n",
        "    pos = nx.spring_layout(graph, seed=42)\n",
        "    cmap = plt.get_cmap('viridis', max(partition.values()) + 1)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    nx.draw(\n",
        "        graph, pos,\n",
        "        node_color=[partition[n] for n in graph.nodes()],\n",
        "        node_size=80, cmap=cmap,\n",
        "        with_labels=True,\n",
        "        labels={n: get_display(arabic_reshaper.reshape(n)) for n in graph.nodes()},\n",
        "        font_family=font_prop.get_name(),\n",
        "        font_size=9,\n",
        "        edge_color=\"lightgray\", alpha=0.7\n",
        "    )\n",
        "    plt.title(\"Word Co-occurrence Graph with Communities\", fontproperties=font_prop, fontsize=16)\n",
        "    plt.savefig(\"community_graph.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø®ÙˆØ¯Ú©Ø§Ø± ÙØ§ÛŒÙ„ PNG\n",
        "    files.download(\"community_graph.png\")\n",
        "\n",
        "# ---- Extract community keywords ----\n",
        "def identify_community_keywords(graph, partition, top_n=10):\n",
        "    communities = {}\n",
        "    for node, comm in partition.items():\n",
        "        communities.setdefault(comm, []).append(node)\n",
        "    results = {}\n",
        "    for comm, nodes in communities.items():\n",
        "        subgraph = graph.subgraph(nodes)\n",
        "        centrality = nx.degree_centrality(subgraph)\n",
        "        ranked = sorted(nodes, key=lambda x: -centrality.get(x, 0))\n",
        "        results[comm] = ranked[:top_n]\n",
        "    return results\n",
        "\n",
        "# ---- Find optimal resolution ----\n",
        "def find_optimal_resolution(graph, target_num_communities=10, start_resolution=0.1, step=0.1, max_iterations=50):\n",
        "    resolution = start_resolution\n",
        "    for _ in range(max_iterations):\n",
        "        partition = detect_communities(graph, resolution)\n",
        "        num_comms = len(set(partition.values()))\n",
        "        print(f\"Resolution {resolution:.2f} â†’ {num_comms} communities\")\n",
        "        if num_comms <= target_num_communities:\n",
        "            return partition, resolution\n",
        "        resolution += step\n",
        "    print(\"âš ï¸ Could not find optimal resolution within limits.\")\n",
        "    return {}, resolution\n",
        "\n",
        "# ---- Main Execution ----\n",
        "word_graph = construct_word_cooccurrence_graph(texts)\n",
        "word_graph.remove_edges_from(nx.selfloop_edges(word_graph))\n",
        "pruned_graph = prune_graph(word_graph)\n",
        "\n",
        "if len(pruned_graph.nodes) == 0:\n",
        "    print(\"âŒ No usable graph after pruning. Try adjusting thresholds.\")\n",
        "else:\n",
        "    partition, res = find_optimal_resolution(pruned_graph, target_num_communities=10)\n",
        "    if partition:\n",
        "        visualize_graph(pruned_graph, partition, font_prop)\n",
        "\n",
        "        keywords = identify_community_keywords(pruned_graph, partition)\n",
        "        for comm_id, words in keywords.items():\n",
        "            print(f\"ðŸ”¹ Community {comm_id}: {words}\")\n",
        "    else:\n",
        "        print(\"âŒ No communities detected.\")\n"
      ],
      "metadata": {
        "id": "XtYIE0sz8fLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Display central words based on Degree and Betweenness Centrality (without arabic_reshaper)\n",
        "\n",
        "def display_top_words_by_centrality(graph, top_n=30):\n",
        "    if nx.is_empty(graph):\n",
        "        print(\"âš ï¸ Graph is empty.\")\n",
        "        return\n",
        "\n",
        "    # Calculate centralities\n",
        "    degree_centrality = nx.degree_centrality(graph)\n",
        "    betweenness_centrality = nx.betweenness_centrality(graph)\n",
        "\n",
        "    # Combine and sort\n",
        "    combined = [\n",
        "        (node, degree_centrality[node], betweenness_centrality[node])\n",
        "        for node in graph.nodes()\n",
        "    ]\n",
        "    combined_sorted = sorted(combined, key=lambda x: (-x[1], -x[2]))[:top_n]\n",
        "\n",
        "    print(\"ðŸ“Š Top Words by Centrality:\")\n",
        "    for word, deg, btw in combined_sorted:\n",
        "        print(f\"{word}: Degree={deg:.4f}, Betweenness={btw:.4f}\")\n",
        "\n",
        "# ðŸŸ¢ Run\n",
        "display_top_words_by_centrality(pruned_graph)\n",
        "\n"
      ],
      "metadata": {
        "id": "c3NRCvgv-R5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}