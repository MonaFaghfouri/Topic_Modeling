{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonaFaghfouri/Topic_Modeling/blob/main/Topic_Modeling_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPlzUFIOIQrK"
      },
      "outputs": [],
      "source": [
        "# Install compatible versions of required libraries\n",
        "!pip install --upgrade --force-reinstall numpy==1.23.5 pandas==1.5.3 gensim openpyxl -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvaIKPZ65yqm"
      },
      "outputs": [],
      "source": [
        "# 1. Upload Excel file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 2. Read the data\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "df = pd.read_excel(next(iter(uploaded)))\n",
        "\n",
        "# 3. Evaluate token list from string format\n",
        "texts = df.iloc[:, 1].astype(str).apply(ast.literal_eval).tolist()\n",
        "\n",
        "# 4. Remove empty documents\n",
        "texts = [doc for doc in texts if len(doc) > 0]\n",
        "\n",
        "# 5. Create dictionary and corpus\n",
        "from gensim import corpora\n",
        "\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "print(f\"Unique tokens before filtering: {len(dictionary)}\")\n",
        "\n",
        "dictionary.filter_extremes(no_below=2, no_above=0.9)\n",
        "print(f\"Unique tokens after filtering: {len(dictionary)}\")\n",
        "\n",
        "if len(dictionary) == 0:\n",
        "    raise ValueError(\"Dictionary is empty after filtering. Adjust thresholds.\")\n",
        "\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# 6. Optimize model: topic count and num_words together\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def optimize_lda_model(dictionary, corpus, texts, topic_range=(5, 16), max_words=20):\n",
        "    best_model = None\n",
        "    best_topic_num = 0\n",
        "    best_num_words = 0\n",
        "    best_coherence = float('-inf')\n",
        "    best_perplexity = float('inf')\n",
        "    best_combination = None\n",
        "    results = []\n",
        "\n",
        "    for num_topics in range(*topic_range):\n",
        "        print(f\"\\nðŸ”„ Testing {num_topics} topics...\")\n",
        "        model = LdaModel(\n",
        "            corpus=corpus,\n",
        "            id2word=dictionary,\n",
        "            num_topics=num_topics,\n",
        "            passes=30,\n",
        "            iterations=600,\n",
        "            random_state=42,\n",
        "            alpha='auto',\n",
        "            eta='auto',\n",
        "            eval_every=None\n",
        "        )\n",
        "\n",
        "        for num_words in range(5, max_words + 1):\n",
        "            topics = model.show_topics(num_topics=-1, num_words=num_words, formatted=False)\n",
        "            topic_word_lists = [[word for word, _ in topic[1]] for topic in topics]\n",
        "\n",
        "            cm = CoherenceModel(\n",
        "                topics=topic_word_lists,\n",
        "                texts=texts,\n",
        "                dictionary=dictionary,\n",
        "                coherence='c_v'\n",
        "            )\n",
        "            coherence = cm.get_coherence()\n",
        "\n",
        "            # Synthetic corpus for perplexity\n",
        "            synthetic_corpus = []\n",
        "            for topic in topics:\n",
        "                words = [word for word, _ in topic[1]]\n",
        "                bow = dictionary.doc2bow(words)\n",
        "                synthetic_corpus.append(bow)\n",
        "            perplexity = model.log_perplexity(synthetic_corpus)\n",
        "\n",
        "            results.append((num_topics, num_words, coherence, perplexity))\n",
        "            print(f\"Topics: {num_topics} | Words: {num_words} â†’ Coherence: {coherence:.4f} | Perplexity: {perplexity:.4f}\")\n",
        "\n",
        "            if coherence > best_coherence or (coherence == best_coherence and perplexity < best_perplexity):\n",
        "                best_model = model\n",
        "                best_topic_num = num_topics\n",
        "                best_num_words = num_words\n",
        "                best_coherence = coherence\n",
        "                best_perplexity = perplexity\n",
        "                best_combination = (num_topics, num_words)\n",
        "\n",
        "    return best_model, best_combination, best_coherence, best_perplexity, results\n",
        "\n",
        "# 7. Run optimization\n",
        "print(\"\\nðŸ” Finding best topic/word configuration...\")\n",
        "best_model, best_combo, best_coh, best_perp, all_results = optimize_lda_model(\n",
        "    dictionary, corpus, texts, topic_range=(5, 16), max_words=20\n",
        ")\n",
        "\n",
        "# 8. Print best configuration\n",
        "print(f\"\\nâœ… Best Model: {best_combo[0]} Topics | {best_combo[1]} Words per Topic\")\n",
        "print(f\"   Coherence: {best_coh:.4f} | Perplexity: {best_perp:.4f}\")\n",
        "\n",
        "# 9. Show best topics\n",
        "print(\"\\nðŸ§  Best Topics (based on optimal settings):\")\n",
        "topics = best_model.show_topics(num_topics=-1, num_words=best_combo[1], formatted=False)\n",
        "for topic_id, words in topics:\n",
        "    word_list = \", \".join(word for word, _ in words)\n",
        "    print(f\"Topic {topic_id}: {word_list}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n48lCQ-7M0t"
      },
      "outputs": [],
      "source": [
        "# 1. Upload files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 2. Libraries\n",
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "\n",
        "# 3. Identify filtered word list file and text file\n",
        "file_names = list(uploaded.keys())\n",
        "sample_words_file = [f for f in file_names if 'word' in f.lower()][0]\n",
        "text_file = [f for f in file_names if f != sample_words_file][0]\n",
        "\n",
        "# 4. Word cleaning function\n",
        "def clean_word(word):\n",
        "    return re.sub(r'[^\\w\\s]', '', word.strip().lower())\n",
        "\n",
        "# 5. Read and clean filtered words\n",
        "df_words = pd.read_excel(sample_words_file)\n",
        "economic_words = df_words.iloc[:, 0].dropna().astype(str).apply(clean_word).tolist()\n",
        "economic_words = set(economic_words)\n",
        "\n",
        "# 6. Read and process text file\n",
        "df_texts = pd.read_excel(text_file)\n",
        "texts_raw = df_texts.iloc[:, 1]\n",
        "\n",
        "texts = []\n",
        "for val in texts_raw:\n",
        "    try:\n",
        "        parsed = ast.literal_eval(str(val))\n",
        "        if isinstance(parsed, list):\n",
        "            cleaned = [clean_word(w) for w in parsed if clean_word(w) in economic_words]\n",
        "            if cleaned:\n",
        "                texts.append(cleaned)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"ðŸ“Š Number of documents containing filtered words: {len(texts)}\")\n",
        "if not texts:\n",
        "    raise ValueError(\"âŒ No documents contain the filtered words.\")\n",
        "\n",
        "# 7. Create dictionary and corpus\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "print(f\"ðŸ”¢ Initial token count: {len(dictionary)}\")\n",
        "dictionary.filter_extremes(no_below=2, no_above=0.9)\n",
        "print(f\"ðŸ”¢ Token count after filtering: {len(dictionary)}\")\n",
        "\n",
        "if len(dictionary) == 0:\n",
        "    raise ValueError(\"âŒ Dictionary is empty after filtering.\")\n",
        "\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# 8. Optimize model based on Coherence and Perplexity\n",
        "def optimize_lda_model(dictionary, corpus, texts, topic_range=(5, 16), max_words=20):\n",
        "    best_model = None\n",
        "    best_topic_num = 0\n",
        "    best_num_words = 0\n",
        "    best_coherence = float('-inf')\n",
        "    best_perplexity = float('inf')\n",
        "    best_combination = None\n",
        "    results = []\n",
        "\n",
        "    for num_topics in range(*topic_range):\n",
        "        print(f\"\\nðŸ”„ Evaluating {num_topics} topics...\")\n",
        "        model = LdaModel(\n",
        "            corpus=corpus,\n",
        "            id2word=dictionary,\n",
        "            num_topics=num_topics,\n",
        "            passes=30,\n",
        "            iterations=600,\n",
        "            random_state=42,\n",
        "            alpha='auto',\n",
        "            eta='auto',\n",
        "            eval_every=None\n",
        "        )\n",
        "\n",
        "        for num_words in range(5, max_words + 1):\n",
        "            topics = model.show_topics(num_topics=-1, num_words=num_words, formatted=False)\n",
        "            topic_word_lists = [[word for word, _ in topic[1]] for topic in topics]\n",
        "\n",
        "            cm = CoherenceModel(\n",
        "                topics=topic_word_lists,\n",
        "                texts=texts,\n",
        "                dictionary=dictionary,\n",
        "                coherence='c_v'\n",
        "            )\n",
        "            coherence = cm.get_coherence()\n",
        "\n",
        "            synthetic_corpus = [\n",
        "                dictionary.doc2bow([word for word, _ in topic[1]])\n",
        "                for topic in topics\n",
        "            ]\n",
        "            perplexity = model.log_perplexity(synthetic_corpus)\n",
        "\n",
        "            results.append((num_topics, num_words, coherence, perplexity))\n",
        "            print(f\"Topics: {num_topics} | Words: {num_words} â†’ Coherence: {coherence:.4f} | Perplexity: {perplexity:.4f}\")\n",
        "\n",
        "            if coherence > best_coherence or (coherence == best_coherence and perplexity < best_perplexity):\n",
        "                best_model = model\n",
        "                best_topic_num = num_topics\n",
        "                best_num_words = num_words\n",
        "                best_coherence = coherence\n",
        "                best_perplexity = perplexity\n",
        "                best_combination = (num_topics, num_words)\n",
        "\n",
        "    return best_model, best_combination, best_coherence, best_perplexity, results\n",
        "\n",
        "# 9. Run optimization\n",
        "print(\"\\nðŸ” Finding the best topic-word configuration...\")\n",
        "best_model, best_combo, best_coh, best_perp, all_results = optimize_lda_model(\n",
        "    dictionary, corpus, texts, topic_range=(5, 16), max_words=20\n",
        ")\n",
        "\n",
        "# 10. Final results\n",
        "print(f\"\\nâœ… Best model: {best_combo[0]} topics | {best_combo[1]} words per topic\")\n",
        "print(f\"   ðŸ“ˆ Coherence: {best_coh:.4f}\")\n",
        "print(f\"   ðŸ“‰ Perplexity: {best_perp:.4f}\")\n",
        "\n",
        "print(\"\\nðŸ§  Final topics based only on filtered words:\")\n",
        "topics = best_model.show_topics(num_topics=-1, num_words=best_combo[1], formatted=False)\n",
        "for topic_id, words in topics:\n",
        "    word_list = \", \".join(word for word, _ in words)\n",
        "    print(f\"Topic {topic_id}: {word_list}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}